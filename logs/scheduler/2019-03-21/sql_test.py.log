[2019-03-21 16:51:28,657] {jobs.py:391} INFO - Started process (PID=156671) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:51:28,662] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 16:51:28,662] {logging_mixin.py:95} INFO - [2019-03-21 16:51:28,662] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:51:28,673] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:51:28,682] {logging_mixin.py:95} INFO - [2019-03-21 16:51:28,682] {models.py:4409} INFO - Creating ORM DAG for sql_test
[2019-03-21 16:51:28,709] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.052 seconds
[2019-03-21 16:52:35,339] {jobs.py:391} INFO - Started process (PID=157730) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:52:35,344] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 16:52:35,344] {logging_mixin.py:95} INFO - [2019-03-21 16:52:35,344] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:52:35,356] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:52:35,381] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.042 seconds
[2019-03-21 16:53:42,023] {jobs.py:391} INFO - Started process (PID=158760) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:53:42,027] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 16:53:42,028] {logging_mixin.py:95} INFO - [2019-03-21 16:53:42,028] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:53:42,037] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:53:42,063] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.040 seconds
[2019-03-21 16:54:48,881] {jobs.py:391} INFO - Started process (PID=159739) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:54:48,887] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 16:54:48,888] {logging_mixin.py:95} INFO - [2019-03-21 16:54:48,887] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:54:48,897] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:54:48,926] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 16:54:49,008] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-01T00:00:00+00:00: scheduled__2015-06-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:54:49,012] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-01 00:00:00+00:00: scheduled__2015-06-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:54:49,017] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2019-03-21 19:50:15.265535+00:00: manual__2019-03-21T19:50:15.265535+00:00, externally triggered: True>
[2019-03-21 16:54:49,023] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2019-03-21 19:54:27.032725+00:00: manual__2019-03-21T19:54:27.032725+00:00, externally triggered: True>
[2019-03-21 16:54:49,036] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 16:54:49,057] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-01 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 16:54:49,060] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2019-03-21 19:50:15.265535+00:00 [scheduled]> in ORM
[2019-03-21 16:54:49,063] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2019-03-21 19:54:27.032725+00:00 [scheduled]> in ORM
[2019-03-21 16:54:49,080] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.199 seconds
[2019-03-21 16:56:13,060] {jobs.py:391} INFO - Started process (PID=161138) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:56:13,064] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 16:56:13,065] {logging_mixin.py:95} INFO - [2019-03-21 16:56:13,065] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:56:13,074] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:56:13,105] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 16:56:13,155] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-02 00:00:00+00:00: scheduled__2015-06-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:56:13,158] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-01 00:00:00+00:00: scheduled__2015-06-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:56:13,163] {logging_mixin.py:95} INFO - [2019-03-21 16:56:13,163] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-01 00:00:00+00:00: scheduled__2015-06-01T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 16:56:13,174] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-02 00:00:00+00:00: scheduled__2015-06-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:56:13,180] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2019-03-21 19:50:15.265535+00:00: manual__2019-03-21T19:50:15.265535+00:00, externally triggered: True>
[2019-03-21 16:56:13,186] {logging_mixin.py:95} INFO - [2019-03-21 16:56:13,185] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2019-03-21 19:50:15.265535+00:00: manual__2019-03-21T19:50:15.265535+00:00, externally triggered: True> successful
[2019-03-21 16:56:13,197] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2019-03-21 19:54:27.032725+00:00: manual__2019-03-21T19:54:27.032725+00:00, externally triggered: True>
[2019-03-21 16:56:13,203] {logging_mixin.py:95} INFO - [2019-03-21 16:56:13,203] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2019-03-21 19:54:27.032725+00:00: manual__2019-03-21T19:54:27.032725+00:00, externally triggered: True> successful
[2019-03-21 16:56:13,217] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 16:56:13,240] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-02 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 16:56:13,252] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.193 seconds
[2019-03-21 16:57:24,992] {jobs.py:391} INFO - Started process (PID=162041) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:57:24,998] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 16:57:24,998] {logging_mixin.py:95} INFO - [2019-03-21 16:57:24,998] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:57:25,009] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:57:25,042] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 16:57:25,098] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-03 00:00:00+00:00: scheduled__2015-06-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:57:25,101] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-02 00:00:00+00:00: scheduled__2015-06-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:57:25,106] {logging_mixin.py:95} INFO - [2019-03-21 16:57:25,106] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-02 00:00:00+00:00: scheduled__2015-06-02T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 16:57:25,120] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-03 00:00:00+00:00: scheduled__2015-06-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:57:25,129] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 16:57:25,149] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-03 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 16:57:25,163] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.171 seconds
[2019-03-21 16:58:36,934] {jobs.py:391} INFO - Started process (PID=162924) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:58:36,939] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 16:58:36,940] {logging_mixin.py:95} INFO - [2019-03-21 16:58:36,940] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:58:36,950] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:58:36,979] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 16:58:37,033] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-04 00:00:00+00:00: scheduled__2015-06-04T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:58:37,036] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-03 00:00:00+00:00: scheduled__2015-06-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:58:37,041] {logging_mixin.py:95} INFO - [2019-03-21 16:58:37,041] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-03 00:00:00+00:00: scheduled__2015-06-03T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 16:58:37,055] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-04 00:00:00+00:00: scheduled__2015-06-04T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:58:37,063] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 16:58:37,081] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-04 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 16:58:37,097] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.163 seconds
[2019-03-21 16:59:48,826] {jobs.py:391} INFO - Started process (PID=163820) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:59:48,831] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 16:59:48,832] {logging_mixin.py:95} INFO - [2019-03-21 16:59:48,832] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:59:48,841] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 16:59:48,874] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 16:59:48,936] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-05 00:00:00+00:00: scheduled__2015-06-05T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:59:48,939] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-04 00:00:00+00:00: scheduled__2015-06-04T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:59:48,944] {logging_mixin.py:95} INFO - [2019-03-21 16:59:48,943] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-04 00:00:00+00:00: scheduled__2015-06-04T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 16:59:48,956] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-05 00:00:00+00:00: scheduled__2015-06-05T00:00:00+00:00, externally triggered: False>
[2019-03-21 16:59:48,965] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 16:59:48,989] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-05 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 16:59:49,006] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.180 seconds
[2019-03-21 17:01:00,812] {jobs.py:391} INFO - Started process (PID=164703) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:01:00,817] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:01:00,817] {logging_mixin.py:95} INFO - [2019-03-21 17:01:00,817] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:01:00,828] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:01:00,862] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:01:00,916] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-06 00:00:00+00:00: scheduled__2015-06-06T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:01:00,920] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-05 00:00:00+00:00: scheduled__2015-06-05T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:01:00,926] {logging_mixin.py:95} INFO - [2019-03-21 17:01:00,925] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-05 00:00:00+00:00: scheduled__2015-06-05T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:01:00,938] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-06 00:00:00+00:00: scheduled__2015-06-06T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:01:00,946] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:01:00,964] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-06 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:01:00,979] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.167 seconds
[2019-03-21 17:02:12,890] {jobs.py:391} INFO - Started process (PID=165626) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:02:12,897] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:02:12,897] {logging_mixin.py:95} INFO - [2019-03-21 17:02:12,897] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:02:12,908] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:02:12,939] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:02:12,992] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-07 00:00:00+00:00: scheduled__2015-06-07T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:02:12,995] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-06 00:00:00+00:00: scheduled__2015-06-06T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:02:13,000] {logging_mixin.py:95} INFO - [2019-03-21 17:02:13,000] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-06 00:00:00+00:00: scheduled__2015-06-06T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:02:13,011] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-07 00:00:00+00:00: scheduled__2015-06-07T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:02:13,020] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:02:13,039] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-07 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:02:13,054] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.164 seconds
[2019-03-21 17:03:24,810] {jobs.py:391} INFO - Started process (PID=166614) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:03:24,815] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:03:24,816] {logging_mixin.py:95} INFO - [2019-03-21 17:03:24,816] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:03:24,825] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:03:24,861] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:03:24,921] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-08 00:00:00+00:00: scheduled__2015-06-08T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:03:24,924] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-07 00:00:00+00:00: scheduled__2015-06-07T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:03:24,929] {logging_mixin.py:95} INFO - [2019-03-21 17:03:24,929] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-07 00:00:00+00:00: scheduled__2015-06-07T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:03:24,943] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-08 00:00:00+00:00: scheduled__2015-06-08T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:03:24,952] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:03:24,976] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-08 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:03:24,991] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.182 seconds
[2019-03-21 17:04:36,900] {jobs.py:391} INFO - Started process (PID=167658) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:04:36,906] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:04:36,906] {logging_mixin.py:95} INFO - [2019-03-21 17:04:36,906] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:04:36,916] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:04:36,944] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:04:36,998] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-09 00:00:00+00:00: scheduled__2015-06-09T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:04:37,001] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-08 00:00:00+00:00: scheduled__2015-06-08T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:04:37,006] {logging_mixin.py:95} INFO - [2019-03-21 17:04:37,006] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-08 00:00:00+00:00: scheduled__2015-06-08T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:04:37,023] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-09 00:00:00+00:00: scheduled__2015-06-09T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:04:37,032] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:04:37,051] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-09 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:04:37,068] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.167 seconds
[2019-03-21 17:05:48,870] {jobs.py:391} INFO - Started process (PID=168565) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:05:48,875] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:05:48,875] {logging_mixin.py:95} INFO - [2019-03-21 17:05:48,875] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:05:48,885] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:05:48,913] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:05:48,969] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-10 00:00:00+00:00: scheduled__2015-06-10T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:05:48,971] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-09 00:00:00+00:00: scheduled__2015-06-09T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:05:48,977] {logging_mixin.py:95} INFO - [2019-03-21 17:05:48,977] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-09 00:00:00+00:00: scheduled__2015-06-09T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:05:48,988] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-10 00:00:00+00:00: scheduled__2015-06-10T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:05:48,997] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:05:49,013] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-10 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:05:49,024] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.154 seconds
[2019-03-21 17:07:00,812] {jobs.py:391} INFO - Started process (PID=169448) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:07:00,817] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:07:00,817] {logging_mixin.py:95} INFO - [2019-03-21 17:07:00,817] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:07:00,828] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:07:00,856] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:07:00,907] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-11 00:00:00+00:00: scheduled__2015-06-11T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:07:00,910] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-10 00:00:00+00:00: scheduled__2015-06-10T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:07:00,915] {logging_mixin.py:95} INFO - [2019-03-21 17:07:00,915] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-10 00:00:00+00:00: scheduled__2015-06-10T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:07:00,926] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-11 00:00:00+00:00: scheduled__2015-06-11T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:07:00,935] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:07:00,955] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-11 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:07:00,971] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.159 seconds
[2019-03-21 17:08:12,863] {jobs.py:391} INFO - Started process (PID=170413) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:08:12,868] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:08:12,869] {logging_mixin.py:95} INFO - [2019-03-21 17:08:12,868] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:08:12,879] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:08:12,912] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:08:12,960] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-12 00:00:00+00:00: scheduled__2015-06-12T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:08:12,963] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-11 00:00:00+00:00: scheduled__2015-06-11T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:08:12,968] {logging_mixin.py:95} INFO - [2019-03-21 17:08:12,968] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-11 00:00:00+00:00: scheduled__2015-06-11T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:08:12,981] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-12 00:00:00+00:00: scheduled__2015-06-12T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:08:12,990] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:08:13,011] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-12 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:08:13,026] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.163 seconds
[2019-03-21 17:09:24,743] {jobs.py:391} INFO - Started process (PID=171448) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:09:24,749] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:09:24,749] {logging_mixin.py:95} INFO - [2019-03-21 17:09:24,749] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:09:24,759] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:09:24,793] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:09:24,852] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-13 00:00:00+00:00: scheduled__2015-06-13T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:09:24,855] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-12 00:00:00+00:00: scheduled__2015-06-12T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:09:24,860] {logging_mixin.py:95} INFO - [2019-03-21 17:09:24,860] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-12 00:00:00+00:00: scheduled__2015-06-12T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:09:24,874] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-13 00:00:00+00:00: scheduled__2015-06-13T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:09:24,883] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:09:24,904] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-13 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:09:24,923] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.180 seconds
[2019-03-21 17:10:36,683] {jobs.py:391} INFO - Started process (PID=172356) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:10:36,688] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:10:36,688] {logging_mixin.py:95} INFO - [2019-03-21 17:10:36,688] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:10:36,697] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:10:36,729] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:10:36,781] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-14 00:00:00+00:00: scheduled__2015-06-14T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:10:36,784] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-13 00:00:00+00:00: scheduled__2015-06-13T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:10:36,789] {logging_mixin.py:95} INFO - [2019-03-21 17:10:36,789] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-13 00:00:00+00:00: scheduled__2015-06-13T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:10:36,800] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-14 00:00:00+00:00: scheduled__2015-06-14T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:10:36,809] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:10:36,828] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-14 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:10:36,841] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.158 seconds
[2019-03-21 17:11:48,649] {jobs.py:391} INFO - Started process (PID=173320) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:11:48,655] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:11:48,656] {logging_mixin.py:95} INFO - [2019-03-21 17:11:48,656] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:11:48,667] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:11:48,700] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:11:48,753] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-15 00:00:00+00:00: scheduled__2015-06-15T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:11:48,756] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-14 00:00:00+00:00: scheduled__2015-06-14T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:11:48,761] {logging_mixin.py:95} INFO - [2019-03-21 17:11:48,761] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-14 00:00:00+00:00: scheduled__2015-06-14T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:11:48,776] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-15 00:00:00+00:00: scheduled__2015-06-15T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:11:48,785] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:11:48,808] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-15 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:11:48,824] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.176 seconds
[2019-03-21 17:13:00,653] {jobs.py:391} INFO - Started process (PID=174203) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:13:00,658] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:13:00,658] {logging_mixin.py:95} INFO - [2019-03-21 17:13:00,658] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:13:00,667] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:13:00,698] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:13:00,747] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-16 00:00:00+00:00: scheduled__2015-06-16T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:13:00,750] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-15 00:00:00+00:00: scheduled__2015-06-15T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:13:00,755] {logging_mixin.py:95} INFO - [2019-03-21 17:13:00,755] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-15 00:00:00+00:00: scheduled__2015-06-15T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:13:00,770] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-16 00:00:00+00:00: scheduled__2015-06-16T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:13:00,778] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:13:00,798] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-16 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:13:00,813] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.160 seconds
[2019-03-21 17:14:12,559] {jobs.py:391} INFO - Started process (PID=175110) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:14:12,563] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:14:12,564] {logging_mixin.py:95} INFO - [2019-03-21 17:14:12,564] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:14:12,573] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:14:12,604] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:14:12,660] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-17 00:00:00+00:00: scheduled__2015-06-17T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:14:12,663] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-16 00:00:00+00:00: scheduled__2015-06-16T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:14:12,668] {logging_mixin.py:95} INFO - [2019-03-21 17:14:12,667] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-16 00:00:00+00:00: scheduled__2015-06-16T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:14:12,681] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-17 00:00:00+00:00: scheduled__2015-06-17T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:14:12,690] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:14:12,712] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-17 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:14:12,726] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.167 seconds
[2019-03-21 17:15:24,513] {jobs.py:391} INFO - Started process (PID=175993) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:15:24,518] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:15:24,518] {logging_mixin.py:95} INFO - [2019-03-21 17:15:24,518] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:15:24,529] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:15:24,559] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:15:24,621] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-18 00:00:00+00:00: scheduled__2015-06-18T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:15:24,625] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-17 00:00:00+00:00: scheduled__2015-06-17T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:15:24,630] {logging_mixin.py:95} INFO - [2019-03-21 17:15:24,630] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-17 00:00:00+00:00: scheduled__2015-06-17T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:15:24,643] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-18 00:00:00+00:00: scheduled__2015-06-18T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:15:24,652] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:15:24,671] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-18 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:15:24,687] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.174 seconds
[2019-03-21 17:16:36,431] {jobs.py:391} INFO - Started process (PID=176958) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:16:36,437] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:16:36,437] {logging_mixin.py:95} INFO - [2019-03-21 17:16:36,437] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:16:36,447] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:16:36,475] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:16:36,525] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-19 00:00:00+00:00: scheduled__2015-06-19T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:16:36,528] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-18 00:00:00+00:00: scheduled__2015-06-18T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:16:36,533] {logging_mixin.py:95} INFO - [2019-03-21 17:16:36,533] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-18 00:00:00+00:00: scheduled__2015-06-18T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:16:36,546] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-19 00:00:00+00:00: scheduled__2015-06-19T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:16:36,555] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:16:36,575] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-19 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:16:36,588] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.157 seconds
[2019-03-21 17:17:48,333] {jobs.py:391} INFO - Started process (PID=177834) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:17:48,339] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:17:48,339] {logging_mixin.py:95} INFO - [2019-03-21 17:17:48,339] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:17:48,349] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:17:48,393] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:17:48,446] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-20 00:00:00+00:00: scheduled__2015-06-20T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:17:48,449] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-19 00:00:00+00:00: scheduled__2015-06-19T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:17:48,454] {logging_mixin.py:95} INFO - [2019-03-21 17:17:48,454] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-19 00:00:00+00:00: scheduled__2015-06-19T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:17:48,470] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-20 00:00:00+00:00: scheduled__2015-06-20T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:17:48,480] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:17:48,498] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-20 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:17:48,513] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.181 seconds
[2019-03-21 17:19:00,212] {jobs.py:391} INFO - Started process (PID=178741) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:19:00,217] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:19:00,218] {logging_mixin.py:95} INFO - [2019-03-21 17:19:00,218] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:19:00,229] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:19:00,260] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:19:00,307] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-21 00:00:00+00:00: scheduled__2015-06-21T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:19:00,310] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-20 00:00:00+00:00: scheduled__2015-06-20T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:19:00,316] {logging_mixin.py:95} INFO - [2019-03-21 17:19:00,316] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-20 00:00:00+00:00: scheduled__2015-06-20T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:19:00,328] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-21 00:00:00+00:00: scheduled__2015-06-21T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:19:00,336] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:19:00,356] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-21 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:19:00,367] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.155 seconds
[2019-03-21 17:20:12,133] {jobs.py:391} INFO - Started process (PID=179625) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:20:12,139] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:20:12,139] {logging_mixin.py:95} INFO - [2019-03-21 17:20:12,139] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:20:12,151] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:20:12,183] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:20:12,237] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-22 00:00:00+00:00: scheduled__2015-06-22T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:20:12,240] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-21 00:00:00+00:00: scheduled__2015-06-21T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:20:12,245] {logging_mixin.py:95} INFO - [2019-03-21 17:20:12,245] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-21 00:00:00+00:00: scheduled__2015-06-21T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:20:12,260] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-22 00:00:00+00:00: scheduled__2015-06-22T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:20:12,269] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:20:12,287] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-22 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:20:12,302] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.169 seconds
[2019-03-21 17:21:24,292] {jobs.py:391} INFO - Started process (PID=180509) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:21:24,298] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:21:24,298] {logging_mixin.py:95} INFO - [2019-03-21 17:21:24,298] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:21:24,308] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:21:24,336] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:21:24,397] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-23 00:00:00+00:00: scheduled__2015-06-23T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:21:24,400] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-22 00:00:00+00:00: scheduled__2015-06-22T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:21:24,405] {logging_mixin.py:95} INFO - [2019-03-21 17:21:24,405] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-22 00:00:00+00:00: scheduled__2015-06-22T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:21:24,421] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-23 00:00:00+00:00: scheduled__2015-06-23T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:21:24,430] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:21:24,449] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-23 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:21:24,466] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.174 seconds
[2019-03-21 17:22:36,279] {jobs.py:391} INFO - Started process (PID=181417) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:22:36,285] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:22:36,285] {logging_mixin.py:95} INFO - [2019-03-21 17:22:36,285] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:22:36,296] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:22:36,325] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:22:36,373] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-24 00:00:00+00:00: scheduled__2015-06-24T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:22:36,377] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-23 00:00:00+00:00: scheduled__2015-06-23T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:22:36,382] {logging_mixin.py:95} INFO - [2019-03-21 17:22:36,382] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-23 00:00:00+00:00: scheduled__2015-06-23T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:22:36,391] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-24 00:00:00+00:00: scheduled__2015-06-24T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:22:36,400] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:22:36,416] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-24 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:22:36,429] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.150 seconds
[2019-03-21 17:23:48,206] {jobs.py:391} INFO - Started process (PID=182301) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:23:48,212] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:23:48,212] {logging_mixin.py:95} INFO - [2019-03-21 17:23:48,212] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:23:48,223] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:23:48,252] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:23:48,306] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-25 00:00:00+00:00: scheduled__2015-06-25T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:23:48,309] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-24 00:00:00+00:00: scheduled__2015-06-24T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:23:48,314] {logging_mixin.py:95} INFO - [2019-03-21 17:23:48,314] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-24 00:00:00+00:00: scheduled__2015-06-24T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:23:48,325] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-25 00:00:00+00:00: scheduled__2015-06-25T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:23:48,334] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:23:48,354] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-25 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:23:48,370] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.164 seconds
[2019-03-21 17:25:00,248] {jobs.py:391} INFO - Started process (PID=183185) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:25:00,254] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:25:00,254] {logging_mixin.py:95} INFO - [2019-03-21 17:25:00,254] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:25:00,265] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:25:00,295] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:25:00,349] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-26 00:00:00+00:00: scheduled__2015-06-26T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:25:00,352] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-25 00:00:00+00:00: scheduled__2015-06-25T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:25:00,357] {logging_mixin.py:95} INFO - [2019-03-21 17:25:00,357] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-25 00:00:00+00:00: scheduled__2015-06-25T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:25:00,368] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-26 00:00:00+00:00: scheduled__2015-06-26T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:25:00,376] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:25:00,395] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-26 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:25:00,408] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.160 seconds
[2019-03-21 17:26:15,222] {jobs.py:391} INFO - Started process (PID=185528) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:26:15,255] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:26:15,256] {logging_mixin.py:95} INFO - [2019-03-21 17:26:15,256] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:26:15,266] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:26:15,348] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:26:15,540] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-27 00:00:00+00:00: scheduled__2015-06-27T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:26:15,544] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-26 00:00:00+00:00: scheduled__2015-06-26T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:26:15,549] {logging_mixin.py:95} INFO - [2019-03-21 17:26:15,549] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-26 00:00:00+00:00: scheduled__2015-06-26T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:26:15,604] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-27 00:00:00+00:00: scheduled__2015-06-27T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:26:15,614] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:26:15,680] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-27 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:26:15,764] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.542 seconds
[2019-03-21 17:27:53,025] {jobs.py:391} INFO - Started process (PID=188197) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:27:53,030] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:27:53,030] {logging_mixin.py:95} INFO - [2019-03-21 17:27:53,030] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:27:53,044] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:27:53,070] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:27:53,117] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-28 00:00:00+00:00: scheduled__2015-06-28T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:27:53,120] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-27 00:00:00+00:00: scheduled__2015-06-27T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:27:53,125] {logging_mixin.py:95} INFO - [2019-03-21 17:27:53,125] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-27 00:00:00+00:00: scheduled__2015-06-27T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:27:53,134] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-28 00:00:00+00:00: scheduled__2015-06-28T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:27:53,144] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:27:53,160] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-28 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:27:53,172] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.147 seconds
[2019-03-21 17:29:07,371] {jobs.py:391} INFO - Started process (PID=191153) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:29:07,397] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:29:07,397] {logging_mixin.py:95} INFO - [2019-03-21 17:29:07,397] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:29:07,410] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:29:07,562] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:29:07,796] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-29 00:00:00+00:00: scheduled__2015-06-29T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:29:07,803] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-28 00:00:00+00:00: scheduled__2015-06-28T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:29:07,813] {logging_mixin.py:95} INFO - [2019-03-21 17:29:07,813] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-28 00:00:00+00:00: scheduled__2015-06-28T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:29:07,895] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-29 00:00:00+00:00: scheduled__2015-06-29T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:29:07,926] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:29:07,991] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-29 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:29:08,085] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.715 seconds
[2019-03-21 17:30:28,769] {jobs.py:391} INFO - Started process (PID=193781) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:30:28,774] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:30:28,775] {logging_mixin.py:95} INFO - [2019-03-21 17:30:28,775] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:30:28,785] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:30:28,857] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:30:29,008] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-06-30 00:00:00+00:00: scheduled__2015-06-30T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:30:29,012] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-29 00:00:00+00:00: scheduled__2015-06-29T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:30:29,018] {logging_mixin.py:95} INFO - [2019-03-21 17:30:29,018] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-29 00:00:00+00:00: scheduled__2015-06-29T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:30:29,061] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-30 00:00:00+00:00: scheduled__2015-06-30T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:30:29,072] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:30:29,120] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-06-30 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:30:29,182] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.413 seconds
[2019-03-21 17:31:43,439] {jobs.py:391} INFO - Started process (PID=196990) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:31:43,445] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:31:43,446] {logging_mixin.py:95} INFO - [2019-03-21 17:31:43,446] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:31:43,462] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:31:43,533] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:31:43,642] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-01 00:00:00+00:00: scheduled__2015-07-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:31:43,646] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-06-30 00:00:00+00:00: scheduled__2015-06-30T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:31:43,651] {logging_mixin.py:95} INFO - [2019-03-21 17:31:43,651] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-06-30 00:00:00+00:00: scheduled__2015-06-30T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:31:43,685] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-01 00:00:00+00:00: scheduled__2015-07-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:31:43,695] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:31:43,735] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-01 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:31:43,764] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.324 seconds
[2019-03-21 17:33:11,916] {jobs.py:391} INFO - Started process (PID=199575) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:33:11,953] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:33:11,954] {logging_mixin.py:95} INFO - [2019-03-21 17:33:11,954] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:33:11,964] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:33:12,056] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:33:12,243] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-02 00:00:00+00:00: scheduled__2015-07-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:33:12,246] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-01 00:00:00+00:00: scheduled__2015-07-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:33:12,252] {logging_mixin.py:95} INFO - [2019-03-21 17:33:12,252] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-01 00:00:00+00:00: scheduled__2015-07-01T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:33:12,323] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-02 00:00:00+00:00: scheduled__2015-07-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:33:12,333] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:33:12,408] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-02 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:33:12,490] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.574 seconds
[2019-03-21 17:34:31,240] {jobs.py:391} INFO - Started process (PID=202574) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:34:31,263] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:34:31,263] {logging_mixin.py:95} INFO - [2019-03-21 17:34:31,263] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:34:31,277] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:34:31,333] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:34:31,449] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-03 00:00:00+00:00: scheduled__2015-07-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:34:31,452] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-02 00:00:00+00:00: scheduled__2015-07-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:34:31,459] {logging_mixin.py:95} INFO - [2019-03-21 17:34:31,458] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-02 00:00:00+00:00: scheduled__2015-07-02T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:34:31,500] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-03 00:00:00+00:00: scheduled__2015-07-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:34:31,511] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:34:31,548] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-03 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:34:31,583] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.344 seconds
[2019-03-21 17:35:54,184] {jobs.py:391} INFO - Started process (PID=205289) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:35:54,230] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:35:54,230] {logging_mixin.py:95} INFO - [2019-03-21 17:35:54,230] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:35:54,665] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:35:54,905] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:35:55,276] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-04 00:00:00+00:00: scheduled__2015-07-04T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:35:55,296] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-03 00:00:00+00:00: scheduled__2015-07-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:35:55,307] {logging_mixin.py:95} INFO - [2019-03-21 17:35:55,307] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-03 00:00:00+00:00: scheduled__2015-07-03T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:35:55,325] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-04 00:00:00+00:00: scheduled__2015-07-04T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:35:55,343] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:35:55,384] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-04 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:35:55,427] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 1.243 seconds
[2019-03-21 17:37:11,433] {jobs.py:391} INFO - Started process (PID=208327) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:37:11,470] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:37:11,470] {logging_mixin.py:95} INFO - [2019-03-21 17:37:11,470] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:37:11,482] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:37:11,584] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:37:11,760] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-05 00:00:00+00:00: scheduled__2015-07-05T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:37:11,764] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-04 00:00:00+00:00: scheduled__2015-07-04T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:37:11,784] {logging_mixin.py:95} INFO - [2019-03-21 17:37:11,784] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-04 00:00:00+00:00: scheduled__2015-07-04T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:37:11,822] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-05 00:00:00+00:00: scheduled__2015-07-05T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:37:11,832] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:37:11,906] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-05 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:37:12,001] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.568 seconds
[2019-03-21 17:38:32,125] {jobs.py:391} INFO - Started process (PID=210960) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:38:32,142] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:38:32,142] {logging_mixin.py:95} INFO - [2019-03-21 17:38:32,142] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:38:32,170] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:38:32,247] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:38:32,381] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-06 00:00:00+00:00: scheduled__2015-07-06T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:38:32,387] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-05 00:00:00+00:00: scheduled__2015-07-05T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:38:32,395] {logging_mixin.py:95} INFO - [2019-03-21 17:38:32,394] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-05 00:00:00+00:00: scheduled__2015-07-05T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:38:32,421] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-06 00:00:00+00:00: scheduled__2015-07-06T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:38:32,440] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:38:32,488] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-06 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:38:32,540] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.416 seconds
[2019-03-21 17:39:49,393] {jobs.py:391} INFO - Started process (PID=213835) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:39:49,423] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:39:49,423] {logging_mixin.py:95} INFO - [2019-03-21 17:39:49,423] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:39:49,435] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:39:49,526] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:39:49,734] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-07 00:00:00+00:00: scheduled__2015-07-07T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:39:49,738] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-06 00:00:00+00:00: scheduled__2015-07-06T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:39:49,744] {logging_mixin.py:95} INFO - [2019-03-21 17:39:49,743] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-06 00:00:00+00:00: scheduled__2015-07-06T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:39:49,812] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-07 00:00:00+00:00: scheduled__2015-07-07T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:39:49,823] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:39:49,884] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-07 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:39:49,954] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.562 seconds
[2019-03-21 17:41:07,562] {jobs.py:391} INFO - Started process (PID=216474) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:41:07,591] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:41:07,591] {logging_mixin.py:95} INFO - [2019-03-21 17:41:07,591] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:41:07,642] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:41:07,738] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:41:07,941] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-08 00:00:00+00:00: scheduled__2015-07-08T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:41:07,945] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-07 00:00:00+00:00: scheduled__2015-07-07T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:41:07,962] {logging_mixin.py:95} INFO - [2019-03-21 17:41:07,962] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-07 00:00:00+00:00: scheduled__2015-07-07T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:41:08,034] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-08 00:00:00+00:00: scheduled__2015-07-08T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:41:08,049] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:41:08,116] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-08 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:41:08,165] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.603 seconds
[2019-03-21 17:42:25,242] {jobs.py:391} INFO - Started process (PID=219472) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:42:25,246] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:42:25,247] {logging_mixin.py:95} INFO - [2019-03-21 17:42:25,247] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:42:25,257] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:42:25,290] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:42:25,335] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-09 00:00:00+00:00: scheduled__2015-07-09T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:42:25,338] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-08 00:00:00+00:00: scheduled__2015-07-08T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:42:25,343] {logging_mixin.py:95} INFO - [2019-03-21 17:42:25,343] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-08 00:00:00+00:00: scheduled__2015-07-08T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:42:25,352] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-09 00:00:00+00:00: scheduled__2015-07-09T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:42:25,360] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:42:25,378] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-09 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:42:25,390] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.148 seconds
[2019-03-21 17:43:47,541] {jobs.py:391} INFO - Started process (PID=222578) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:43:47,576] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:43:47,576] {logging_mixin.py:95} INFO - [2019-03-21 17:43:47,576] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:43:47,587] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:43:47,700] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:43:47,906] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-10 00:00:00+00:00: scheduled__2015-07-10T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:43:47,910] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-09 00:00:00+00:00: scheduled__2015-07-09T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:43:47,916] {logging_mixin.py:95} INFO - [2019-03-21 17:43:47,915] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-09 00:00:00+00:00: scheduled__2015-07-09T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:43:48,002] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-10 00:00:00+00:00: scheduled__2015-07-10T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:43:48,011] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:43:48,082] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-10 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:43:48,147] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.606 seconds
[2019-03-21 17:45:06,047] {jobs.py:391} INFO - Started process (PID=225727) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:45:06,058] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:45:06,058] {logging_mixin.py:95} INFO - [2019-03-21 17:45:06,058] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:45:06,080] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:45:06,170] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:45:06,300] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-11 00:00:00+00:00: scheduled__2015-07-11T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:45:06,304] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-10 00:00:00+00:00: scheduled__2015-07-10T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:45:06,309] {logging_mixin.py:95} INFO - [2019-03-21 17:45:06,309] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-10 00:00:00+00:00: scheduled__2015-07-10T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:45:06,340] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-11 00:00:00+00:00: scheduled__2015-07-11T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:45:06,350] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:45:06,439] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-11 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:45:06,515] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.469 seconds
[2019-03-21 17:46:26,200] {jobs.py:391} INFO - Started process (PID=228744) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:46:26,237] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:46:26,237] {logging_mixin.py:95} INFO - [2019-03-21 17:46:26,237] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:46:26,268] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:46:26,359] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:46:26,616] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-12 00:00:00+00:00: scheduled__2015-07-12T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:46:26,619] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-11 00:00:00+00:00: scheduled__2015-07-11T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:46:26,640] {logging_mixin.py:95} INFO - [2019-03-21 17:46:26,640] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-11 00:00:00+00:00: scheduled__2015-07-11T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:46:26,705] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-12 00:00:00+00:00: scheduled__2015-07-12T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:46:26,717] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:46:26,806] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-12 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:46:26,883] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.683 seconds
[2019-03-21 17:47:46,955] {jobs.py:391} INFO - Started process (PID=231744) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:47:47,002] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:47:47,002] {logging_mixin.py:95} INFO - [2019-03-21 17:47:47,002] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:47:47,251] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:47:47,549] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:47:47,752] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-13 00:00:00+00:00: scheduled__2015-07-13T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:47:47,756] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-12 00:00:00+00:00: scheduled__2015-07-12T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:47:47,763] {logging_mixin.py:95} INFO - [2019-03-21 17:47:47,763] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-12 00:00:00+00:00: scheduled__2015-07-12T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:47:47,810] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-13 00:00:00+00:00: scheduled__2015-07-13T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:47:47,821] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:47:47,869] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-13 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:47:47,895] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.940 seconds
[2019-03-21 17:49:08,725] {jobs.py:391} INFO - Started process (PID=234522) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:49:08,761] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:49:08,761] {logging_mixin.py:95} INFO - [2019-03-21 17:49:08,761] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:49:08,773] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:49:08,860] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:49:09,075] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-14 00:00:00+00:00: scheduled__2015-07-14T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:49:09,078] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-13 00:00:00+00:00: scheduled__2015-07-13T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:49:09,085] {logging_mixin.py:95} INFO - [2019-03-21 17:49:09,085] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-13 00:00:00+00:00: scheduled__2015-07-13T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:49:09,150] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-14 00:00:00+00:00: scheduled__2015-07-14T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:49:09,160] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:49:09,255] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-14 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:49:09,323] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.598 seconds
[2019-03-21 17:50:23,992] {jobs.py:391} INFO - Started process (PID=236174) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:50:23,998] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:50:23,998] {logging_mixin.py:95} INFO - [2019-03-21 17:50:23,998] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:50:24,010] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:50:24,039] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:50:24,104] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-15 00:00:00+00:00: scheduled__2015-07-15T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:50:24,107] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-14 00:00:00+00:00: scheduled__2015-07-14T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:50:24,112] {logging_mixin.py:95} INFO - [2019-03-21 17:50:24,112] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-14 00:00:00+00:00: scheduled__2015-07-14T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:50:24,123] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-15 00:00:00+00:00: scheduled__2015-07-15T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:50:24,132] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:50:24,150] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-15 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:50:24,162] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.170 seconds
[2019-03-21 17:51:35,884] {jobs.py:391} INFO - Started process (PID=237061) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:51:35,889] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:51:35,889] {logging_mixin.py:95} INFO - [2019-03-21 17:51:35,889] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:51:35,900] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:51:35,932] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:51:35,980] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-16 00:00:00+00:00: scheduled__2015-07-16T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:51:35,983] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-15 00:00:00+00:00: scheduled__2015-07-15T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:51:35,988] {logging_mixin.py:95} INFO - [2019-03-21 17:51:35,988] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-15 00:00:00+00:00: scheduled__2015-07-15T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:51:36,000] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-16 00:00:00+00:00: scheduled__2015-07-16T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:51:36,014] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:51:36,030] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-16 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:51:36,044] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.160 seconds
[2019-03-21 17:52:47,818] {jobs.py:391} INFO - Started process (PID=237973) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:52:47,824] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:52:47,824] {logging_mixin.py:95} INFO - [2019-03-21 17:52:47,824] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:52:47,836] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:52:47,867] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:52:47,912] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-17 00:00:00+00:00: scheduled__2015-07-17T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:52:47,915] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-16 00:00:00+00:00: scheduled__2015-07-16T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:52:47,920] {logging_mixin.py:95} INFO - [2019-03-21 17:52:47,920] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-16 00:00:00+00:00: scheduled__2015-07-16T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:52:47,932] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-17 00:00:00+00:00: scheduled__2015-07-17T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:52:47,941] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:52:47,957] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-17 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:52:47,969] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.152 seconds
[2019-03-21 17:53:59,829] {jobs.py:391} INFO - Started process (PID=238860) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:53:59,834] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:53:59,835] {logging_mixin.py:95} INFO - [2019-03-21 17:53:59,835] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:53:59,847] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:53:59,887] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:53:59,940] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-18 00:00:00+00:00: scheduled__2015-07-18T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:53:59,944] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-17 00:00:00+00:00: scheduled__2015-07-17T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:53:59,949] {logging_mixin.py:95} INFO - [2019-03-21 17:53:59,949] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-17 00:00:00+00:00: scheduled__2015-07-17T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:53:59,963] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-18 00:00:00+00:00: scheduled__2015-07-18T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:53:59,972] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:53:59,992] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-18 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:54:00,005] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.176 seconds
[2019-03-21 17:55:11,849] {jobs.py:391} INFO - Started process (PID=239747) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:55:11,854] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:55:11,855] {logging_mixin.py:95} INFO - [2019-03-21 17:55:11,855] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:55:11,866] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:55:11,896] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:55:11,956] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-19 00:00:00+00:00: scheduled__2015-07-19T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:55:11,959] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-18 00:00:00+00:00: scheduled__2015-07-18T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:55:11,964] {logging_mixin.py:95} INFO - [2019-03-21 17:55:11,964] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-18 00:00:00+00:00: scheduled__2015-07-18T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:55:11,979] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-19 00:00:00+00:00: scheduled__2015-07-19T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:55:11,988] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:55:12,006] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-19 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:55:12,018] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.169 seconds
[2019-03-21 17:56:23,867] {jobs.py:391} INFO - Started process (PID=240659) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:56:23,873] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:56:23,873] {logging_mixin.py:95} INFO - [2019-03-21 17:56:23,873] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:56:23,885] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:56:23,915] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:56:23,973] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-20 00:00:00+00:00: scheduled__2015-07-20T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:56:23,977] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-19 00:00:00+00:00: scheduled__2015-07-19T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:56:23,982] {logging_mixin.py:95} INFO - [2019-03-21 17:56:23,982] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-19 00:00:00+00:00: scheduled__2015-07-19T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:56:23,994] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-20 00:00:00+00:00: scheduled__2015-07-20T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:56:24,003] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:56:24,023] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-20 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:56:24,037] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.170 seconds
[2019-03-21 17:57:35,763] {jobs.py:391} INFO - Started process (PID=241545) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:57:35,768] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:57:35,769] {logging_mixin.py:95} INFO - [2019-03-21 17:57:35,769] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:57:35,781] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:57:35,818] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:57:35,869] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-21 00:00:00+00:00: scheduled__2015-07-21T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:57:35,872] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-20 00:00:00+00:00: scheduled__2015-07-20T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:57:35,877] {logging_mixin.py:95} INFO - [2019-03-21 17:57:35,877] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-20 00:00:00+00:00: scheduled__2015-07-20T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:57:35,890] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-21 00:00:00+00:00: scheduled__2015-07-21T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:57:35,899] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:57:35,920] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-21 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:57:35,932] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.169 seconds
[2019-03-21 17:58:47,699] {jobs.py:391} INFO - Started process (PID=242426) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:58:47,705] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:58:47,705] {logging_mixin.py:95} INFO - [2019-03-21 17:58:47,705] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:58:47,717] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:58:47,748] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:58:47,800] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-22 00:00:00+00:00: scheduled__2015-07-22T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:58:47,804] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-21 00:00:00+00:00: scheduled__2015-07-21T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:58:47,809] {logging_mixin.py:95} INFO - [2019-03-21 17:58:47,809] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-21 00:00:00+00:00: scheduled__2015-07-21T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:58:47,819] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-22 00:00:00+00:00: scheduled__2015-07-22T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:58:47,828] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:58:47,846] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-22 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:58:47,861] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.162 seconds
[2019-03-21 17:59:59,574] {jobs.py:391} INFO - Started process (PID=243313) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:59:59,579] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 17:59:59,580] {logging_mixin.py:95} INFO - [2019-03-21 17:59:59,580] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:59:59,592] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 17:59:59,623] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 17:59:59,685] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-23 00:00:00+00:00: scheduled__2015-07-23T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:59:59,689] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-22 00:00:00+00:00: scheduled__2015-07-22T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:59:59,694] {logging_mixin.py:95} INFO - [2019-03-21 17:59:59,694] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-22 00:00:00+00:00: scheduled__2015-07-22T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 17:59:59,708] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-23 00:00:00+00:00: scheduled__2015-07-23T00:00:00+00:00, externally triggered: False>
[2019-03-21 17:59:59,717] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 17:59:59,740] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-23 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 17:59:59,758] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.184 seconds
[2019-03-21 18:01:11,523] {jobs.py:391} INFO - Started process (PID=244238) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:01:11,529] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:01:11,529] {logging_mixin.py:95} INFO - [2019-03-21 18:01:11,529] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:01:11,541] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:01:11,571] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:01:11,623] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-24 00:00:00+00:00: scheduled__2015-07-24T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:01:11,626] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-23 00:00:00+00:00: scheduled__2015-07-23T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:01:11,631] {logging_mixin.py:95} INFO - [2019-03-21 18:01:11,631] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-23 00:00:00+00:00: scheduled__2015-07-23T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:01:11,642] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-24 00:00:00+00:00: scheduled__2015-07-24T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:01:11,651] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:01:11,671] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-24 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:01:11,686] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.163 seconds
[2019-03-21 18:02:23,455] {jobs.py:391} INFO - Started process (PID=245125) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:02:23,460] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:02:23,461] {logging_mixin.py:95} INFO - [2019-03-21 18:02:23,461] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:02:23,473] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:02:23,505] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:02:23,557] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-25 00:00:00+00:00: scheduled__2015-07-25T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:02:23,561] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-24 00:00:00+00:00: scheduled__2015-07-24T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:02:23,566] {logging_mixin.py:95} INFO - [2019-03-21 18:02:23,566] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-24 00:00:00+00:00: scheduled__2015-07-24T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:02:23,577] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-25 00:00:00+00:00: scheduled__2015-07-25T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:02:23,586] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:02:23,605] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-25 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:02:23,622] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.167 seconds
[2019-03-21 18:03:35,370] {jobs.py:391} INFO - Started process (PID=558) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:03:35,377] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:03:35,377] {logging_mixin.py:95} INFO - [2019-03-21 18:03:35,377] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:03:35,387] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:03:35,417] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:03:35,477] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-26 00:00:00+00:00: scheduled__2015-07-26T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:03:35,480] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-25 00:00:00+00:00: scheduled__2015-07-25T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:03:35,485] {logging_mixin.py:95} INFO - [2019-03-21 18:03:35,485] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-25 00:00:00+00:00: scheduled__2015-07-25T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:03:35,498] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-26 00:00:00+00:00: scheduled__2015-07-26T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:03:35,506] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:03:35,528] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-26 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:03:35,541] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.171 seconds
[2019-03-21 18:04:47,377] {jobs.py:391} INFO - Started process (PID=1445) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:04:47,383] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:04:47,384] {logging_mixin.py:95} INFO - [2019-03-21 18:04:47,384] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:04:47,394] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:04:47,427] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:04:47,490] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-27 00:00:00+00:00: scheduled__2015-07-27T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:04:47,494] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-26 00:00:00+00:00: scheduled__2015-07-26T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:04:47,499] {logging_mixin.py:95} INFO - [2019-03-21 18:04:47,499] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-26 00:00:00+00:00: scheduled__2015-07-26T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:04:47,513] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-27 00:00:00+00:00: scheduled__2015-07-27T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:04:47,521] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:04:47,546] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-27 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:04:47,561] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.183 seconds
[2019-03-21 18:05:59,387] {jobs.py:391} INFO - Started process (PID=2357) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:05:59,394] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:05:59,394] {logging_mixin.py:95} INFO - [2019-03-21 18:05:59,394] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:05:59,405] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:05:59,439] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:05:59,495] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-28 00:00:00+00:00: scheduled__2015-07-28T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:05:59,498] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-27 00:00:00+00:00: scheduled__2015-07-27T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:05:59,503] {logging_mixin.py:95} INFO - [2019-03-21 18:05:59,503] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-27 00:00:00+00:00: scheduled__2015-07-27T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:05:59,520] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-28 00:00:00+00:00: scheduled__2015-07-28T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:05:59,529] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:05:59,552] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-28 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:05:59,569] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.182 seconds
[2019-03-21 18:07:11,322] {jobs.py:391} INFO - Started process (PID=3270) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:07:11,327] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:07:11,327] {logging_mixin.py:95} INFO - [2019-03-21 18:07:11,327] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:07:11,339] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:07:11,375] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:07:11,444] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-29 00:00:00+00:00: scheduled__2015-07-29T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:07:11,448] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-28 00:00:00+00:00: scheduled__2015-07-28T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:07:11,453] {logging_mixin.py:95} INFO - [2019-03-21 18:07:11,453] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-28 00:00:00+00:00: scheduled__2015-07-28T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:07:11,467] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-29 00:00:00+00:00: scheduled__2015-07-29T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:07:11,475] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:07:11,497] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-29 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:07:11,511] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.189 seconds
[2019-03-21 18:08:23,284] {jobs.py:391} INFO - Started process (PID=4151) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:08:23,291] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:08:23,291] {logging_mixin.py:95} INFO - [2019-03-21 18:08:23,291] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:08:23,303] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:08:23,336] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:08:23,391] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-30 00:00:00+00:00: scheduled__2015-07-30T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:08:23,394] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-29 00:00:00+00:00: scheduled__2015-07-29T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:08:23,399] {logging_mixin.py:95} INFO - [2019-03-21 18:08:23,399] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-29 00:00:00+00:00: scheduled__2015-07-29T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:08:23,411] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-30 00:00:00+00:00: scheduled__2015-07-30T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:08:23,420] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:08:23,442] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-30 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:08:23,457] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.173 seconds
[2019-03-21 18:09:35,212] {jobs.py:391} INFO - Started process (PID=5063) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:09:35,216] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:09:35,217] {logging_mixin.py:95} INFO - [2019-03-21 18:09:35,217] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:09:35,227] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:09:35,254] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:09:35,308] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-07-31 00:00:00+00:00: scheduled__2015-07-31T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:09:35,311] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-30 00:00:00+00:00: scheduled__2015-07-30T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:09:35,316] {logging_mixin.py:95} INFO - [2019-03-21 18:09:35,316] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-30 00:00:00+00:00: scheduled__2015-07-30T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:09:35,328] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-31 00:00:00+00:00: scheduled__2015-07-31T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:09:35,336] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:09:35,353] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-07-31 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:09:35,366] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.154 seconds
[2019-03-21 18:10:47,153] {jobs.py:391} INFO - Started process (PID=5962) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:10:47,159] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:10:47,159] {logging_mixin.py:95} INFO - [2019-03-21 18:10:47,159] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:10:47,173] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:10:47,208] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:10:47,265] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-08-01 00:00:00+00:00: scheduled__2015-08-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:10:47,268] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-07-31 00:00:00+00:00: scheduled__2015-07-31T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:10:47,273] {logging_mixin.py:95} INFO - [2019-03-21 18:10:47,273] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-07-31 00:00:00+00:00: scheduled__2015-07-31T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:10:47,287] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-08-01 00:00:00+00:00: scheduled__2015-08-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:10:47,296] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:10:47,319] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-08-01 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:10:47,337] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.184 seconds
[2019-03-21 18:11:59,087] {jobs.py:391} INFO - Started process (PID=6891) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:11:59,092] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:11:59,092] {logging_mixin.py:95} INFO - [2019-03-21 18:11:59,092] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:11:59,103] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:11:59,132] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:11:59,188] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-08-02 00:00:00+00:00: scheduled__2015-08-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:11:59,191] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-08-01 00:00:00+00:00: scheduled__2015-08-01T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:11:59,197] {logging_mixin.py:95} INFO - [2019-03-21 18:11:59,197] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-08-01 00:00:00+00:00: scheduled__2015-08-01T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:11:59,210] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-08-02 00:00:00+00:00: scheduled__2015-08-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:11:59,219] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:11:59,242] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-08-02 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:11:59,259] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.172 seconds
[2019-03-21 18:13:11,042] {jobs.py:391} INFO - Started process (PID=7815) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:13:11,047] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:13:11,047] {logging_mixin.py:95} INFO - [2019-03-21 18:13:11,047] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:13:11,059] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:13:11,093] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:13:11,156] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-08-03 00:00:00+00:00: scheduled__2015-08-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:13:11,160] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-08-02 00:00:00+00:00: scheduled__2015-08-02T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:13:11,165] {logging_mixin.py:95} INFO - [2019-03-21 18:13:11,165] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-08-02 00:00:00+00:00: scheduled__2015-08-02T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:13:11,179] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-08-03 00:00:00+00:00: scheduled__2015-08-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:13:11,187] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:13:11,206] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-08-03 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:13:11,223] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.181 seconds
[2019-03-21 18:14:22,881] {jobs.py:391} INFO - Started process (PID=8733) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:14:22,887] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:14:22,887] {logging_mixin.py:95} INFO - [2019-03-21 18:14:22,887] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:14:22,898] {jobs.py:1687} INFO - DAG(s) dict_keys(['sql_test']) retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:14:22,926] {jobs.py:1422} INFO - Processing sql_test
[2019-03-21 18:14:22,980] {jobs.py:1426} INFO - Created <DagRun sql_test @ 2015-08-04 00:00:00+00:00: scheduled__2015-08-04T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:14:22,983] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-08-03 00:00:00+00:00: scheduled__2015-08-03T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:14:22,988] {logging_mixin.py:95} INFO - [2019-03-21 18:14:22,988] {models.py:5266} INFO - Marking run <DagRun sql_test @ 2015-08-03 00:00:00+00:00: scheduled__2015-08-03T00:00:00+00:00, externally triggered: False> successful
[2019-03-21 18:14:23,000] {jobs.py:917} INFO - Examining DAG run <DagRun sql_test @ 2015-08-04 00:00:00+00:00: scheduled__2015-08-04T00:00:00+00:00, externally triggered: False>
[2019-03-21 18:14:23,008] {jobs.py:626} INFO - Skipping SLA check for <DAG: sql_test> because no tasks in DAG have SLAs
[2019-03-21 18:14:23,029] {jobs.py:1752} INFO - Creating / updating <TaskInstance: sql_test.custom_ETL 2015-08-04 00:00:00+00:00 [scheduled]> in ORM
[2019-03-21 18:14:23,042] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.161 seconds
[2019-03-21 18:15:34,755] {jobs.py:391} INFO - Started process (PID=9623) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:15:34,761] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:15:34,761] {logging_mixin.py:95} INFO - [2019-03-21 18:15:34,761] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:15:34,772] {logging_mixin.py:95} INFO - [2019-03-21 18:15:34,763] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 38
    mssql = = MssqlPyodbc()
            ^
SyntaxError: invalid syntax
[2019-03-21 18:15:34,773] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:15:34,796] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.041 seconds
[2019-03-21 18:16:41,455] {jobs.py:391} INFO - Started process (PID=10429) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:16:41,461] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:16:41,462] {logging_mixin.py:95} INFO - [2019-03-21 18:16:41,462] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:16:41,472] {logging_mixin.py:95} INFO - [2019-03-21 18:16:41,471] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 38, in __init__
    mssql = MssqlPyodbc()
TypeError: 'module' object is not callable
[2019-03-21 18:16:41,473] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:16:41,493] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.038 seconds
[2019-03-21 18:17:48,152] {jobs.py:391} INFO - Started process (PID=11226) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:17:48,157] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:17:48,158] {logging_mixin.py:95} INFO - [2019-03-21 18:17:48,158] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:17:48,169] {logging_mixin.py:95} INFO - [2019-03-21 18:17:48,167] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 38, in __init__
    mssql = MssqlPyodbc()
TypeError: 'module' object is not callable
[2019-03-21 18:17:48,169] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:17:48,187] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.035 seconds
[2019-03-21 18:18:54,820] {jobs.py:391} INFO - Started process (PID=12025) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:18:54,826] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:18:54,826] {logging_mixin.py:95} INFO - [2019-03-21 18:18:54,826] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:18:54,838] {logging_mixin.py:95} INFO - [2019-03-21 18:18:54,836] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 38, in __init__
    mssql = MssqlPyodbc()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 34, in __init__
    super(MssqlPyodbcHook, self).__init__(*args, **kwargs)
NameError: name 'MssqlPyodbcHook' is not defined
[2019-03-21 18:18:54,838] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:18:54,860] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.040 seconds
[2019-03-21 18:20:01,520] {jobs.py:391} INFO - Started process (PID=12822) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:20:01,524] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:20:01,525] {logging_mixin.py:95} INFO - [2019-03-21 18:20:01,525] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:20:01,537] {logging_mixin.py:95} INFO - [2019-03-21 18:20:01,535] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 114, in get_conn
    connection_string = self.get_uri()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 61, in get_uri
    server=conn.host,
AttributeError: 'dict' object has no attribute 'host'
[2019-03-21 18:20:01,537] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:20:01,555] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.036 seconds
[2019-03-21 18:21:08,283] {jobs.py:391} INFO - Started process (PID=13638) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:21:08,289] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:21:08,289] {logging_mixin.py:95} INFO - [2019-03-21 18:21:08,289] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:21:08,303] {logging_mixin.py:95} INFO - [2019-03-21 18:21:08,300] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 114, in get_conn
    connection_string = self.get_uri()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 61, in get_uri
    server=conn.host,
AttributeError: 'dict' object has no attribute 'host'
[2019-03-21 18:21:08,303] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:21:08,320] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 0.037 seconds
[2019-03-21 18:22:14,901] {jobs.py:391} INFO - Started process (PID=14432) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:22:14,906] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:22:14,906] {logging_mixin.py:95} INFO - [2019-03-21 18:22:14,906] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:23:44,963] {logging_mixin.py:95} INFO - [2019-03-21 18:23:44,963] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:23:44,965] {logging_mixin.py:95} INFO - [2019-03-21 18:23:44,963] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 115, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:23:44,966] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:23:44,990] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.090 seconds
[2019-03-21 18:24:50,696] {jobs.py:391} INFO - Started process (PID=15862) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:24:50,702] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:24:50,702] {logging_mixin.py:95} INFO - [2019-03-21 18:24:50,702] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:26:20,723] {logging_mixin.py:95} INFO - [2019-03-21 18:26:20,723] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:26:20,726] {logging_mixin.py:95} INFO - [2019-03-21 18:26:20,723] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 115, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:26:20,726] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:26:20,749] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.052 seconds
[2019-03-21 18:27:26,519] {jobs.py:391} INFO - Started process (PID=17287) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:27:26,526] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:27:26,526] {logging_mixin.py:95} INFO - [2019-03-21 18:27:26,526] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:28:56,544] {logging_mixin.py:95} INFO - [2019-03-21 18:28:56,544] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:28:56,547] {logging_mixin.py:95} INFO - [2019-03-21 18:28:56,545] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 115, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:28:56,547] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:28:56,567] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.048 seconds
[2019-03-21 18:30:02,353] {jobs.py:391} INFO - Started process (PID=18711) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:30:02,360] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:30:02,360] {logging_mixin.py:95} INFO - [2019-03-21 18:30:02,360] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:31:32,380] {logging_mixin.py:95} INFO - [2019-03-21 18:31:32,379] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:31:32,382] {logging_mixin.py:95} INFO - [2019-03-21 18:31:32,380] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 115, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:31:32,382] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:31:32,401] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.048 seconds
[2019-03-21 18:32:38,220] {jobs.py:391} INFO - Started process (PID=20566) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:32:38,225] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:32:38,226] {logging_mixin.py:95} INFO - [2019-03-21 18:32:38,225] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:34:08,245] {logging_mixin.py:95} INFO - [2019-03-21 18:34:08,245] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:34:08,248] {logging_mixin.py:95} INFO - [2019-03-21 18:34:08,245] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 115, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:34:08,248] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:34:08,266] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.046 seconds
[2019-03-21 18:35:14,024] {jobs.py:391} INFO - Started process (PID=22549) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:35:14,031] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:35:14,031] {logging_mixin.py:95} INFO - [2019-03-21 18:35:14,031] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:36:44,049] {logging_mixin.py:95} INFO - [2019-03-21 18:36:44,049] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:36:44,052] {logging_mixin.py:95} INFO - [2019-03-21 18:36:44,050] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 115, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:36:44,052] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:36:44,071] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.046 seconds
[2019-03-21 18:37:49,854] {jobs.py:391} INFO - Started process (PID=24374) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:37:49,860] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:37:49,860] {logging_mixin.py:95} INFO - [2019-03-21 18:37:49,860] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:39:19,879] {logging_mixin.py:95} INFO - [2019-03-21 18:39:19,879] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:39:19,882] {logging_mixin.py:95} INFO - [2019-03-21 18:39:19,879] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 115, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:39:19,882] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:39:19,905] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.051 seconds
[2019-03-21 18:40:25,782] {jobs.py:391} INFO - Started process (PID=26066) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:40:25,787] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:40:25,787] {logging_mixin.py:95} INFO - [2019-03-21 18:40:25,787] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:41:55,806] {logging_mixin.py:95} INFO - [2019-03-21 18:41:55,806] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:41:55,808] {logging_mixin.py:95} INFO - [2019-03-21 18:41:55,806] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 115, in get_conn
    def get_conn(self):
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:41:55,809] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:41:55,827] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.045 seconds
[2019-03-21 18:43:01,618] {jobs.py:391} INFO - Started process (PID=27478) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:43:01,623] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:43:01,623] {logging_mixin.py:95} INFO - [2019-03-21 18:43:01,623] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:43:01,642] {logging_mixin.py:95} INFO - [2019-03-21 18:43:01,642] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 18:44:31,650] {logging_mixin.py:95} INFO - [2019-03-21 18:44:31,650] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:44:31,653] {logging_mixin.py:95} INFO - [2019-03-21 18:44:31,651] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:44:31,653] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:44:31,670] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.052 seconds
[2019-03-21 18:45:37,396] {jobs.py:391} INFO - Started process (PID=28897) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:45:37,401] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:45:37,402] {logging_mixin.py:95} INFO - [2019-03-21 18:45:37,402] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:45:37,422] {logging_mixin.py:95} INFO - [2019-03-21 18:45:37,422] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 18:47:07,431] {logging_mixin.py:95} INFO - [2019-03-21 18:47:07,431] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:47:07,434] {logging_mixin.py:95} INFO - [2019-03-21 18:47:07,431] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:47:07,434] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:47:07,451] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.055 seconds
[2019-03-21 18:48:13,276] {jobs.py:391} INFO - Started process (PID=30354) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:48:13,281] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:48:13,282] {logging_mixin.py:95} INFO - [2019-03-21 18:48:13,282] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:48:13,302] {logging_mixin.py:95} INFO - [2019-03-21 18:48:13,302] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 18:48:13,303] {logging_mixin.py:95} INFO - DRIVER={ODBC Driver 17 for SQL Server};Server=tcp:172.27.16.212,5555;DATABASE=DataEngineering;Persist Security Info=True;UID=rafael.sandroni;PWD=su4R*VO7i;MultipleActiveResultSets=False;Connection Timeout=30;
[2019-03-21 18:49:43,312] {logging_mixin.py:95} INFO - [2019-03-21 18:49:43,312] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:49:43,314] {logging_mixin.py:95} INFO - [2019-03-21 18:49:43,312] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:49:43,314] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:49:43,335] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.059 seconds
[2019-03-21 18:50:49,126] {jobs.py:391} INFO - Started process (PID=31787) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:50:49,131] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:50:49,132] {logging_mixin.py:95} INFO - [2019-03-21 18:50:49,132] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:50:49,149] {logging_mixin.py:95} INFO - [2019-03-21 18:50:49,149] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 18:52:19,159] {logging_mixin.py:95} INFO - [2019-03-21 18:52:19,159] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:52:19,161] {logging_mixin.py:95} INFO - [2019-03-21 18:52:19,159] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:52:19,161] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:52:19,176] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.049 seconds
[2019-03-21 18:53:24,895] {jobs.py:391} INFO - Started process (PID=33208) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:53:24,901] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:53:24,901] {logging_mixin.py:95} INFO - [2019-03-21 18:53:24,901] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:53:24,925] {logging_mixin.py:95} INFO - [2019-03-21 18:53:24,925] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 18:54:54,935] {logging_mixin.py:95} INFO - [2019-03-21 18:54:54,935] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:54:54,937] {logging_mixin.py:95} INFO - [2019-03-21 18:54:54,935] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:54:54,938] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:54:54,951] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.056 seconds
[2019-03-21 18:56:00,730] {jobs.py:391} INFO - Started process (PID=34636) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:56:00,737] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:56:00,737] {logging_mixin.py:95} INFO - [2019-03-21 18:56:00,737] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:56:00,757] {logging_mixin.py:95} INFO - [2019-03-21 18:56:00,757] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 18:57:30,767] {logging_mixin.py:95} INFO - [2019-03-21 18:57:30,767] {timeout.py:41} ERROR - Process timed out
[2019-03-21 18:57:30,770] {logging_mixin.py:95} INFO - [2019-03-21 18:57:30,767] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 18:57:30,770] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:57:30,783] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.053 seconds
[2019-03-21 18:58:36,542] {jobs.py:391} INFO - Started process (PID=36094) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:58:36,548] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 18:58:36,549] {logging_mixin.py:95} INFO - [2019-03-21 18:58:36,548] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 18:58:36,566] {logging_mixin.py:95} INFO - [2019-03-21 18:58:36,566] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:00:06,575] {logging_mixin.py:95} INFO - [2019-03-21 19:00:06,575] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:00:06,577] {logging_mixin.py:95} INFO - [2019-03-21 19:00:06,575] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:00:06,577] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:00:06,590] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.048 seconds
[2019-03-21 19:01:12,376] {jobs.py:391} INFO - Started process (PID=37553) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:01:12,381] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:01:12,381] {logging_mixin.py:95} INFO - [2019-03-21 19:01:12,381] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:01:12,400] {logging_mixin.py:95} INFO - [2019-03-21 19:01:12,400] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:02:42,409] {logging_mixin.py:95} INFO - [2019-03-21 19:02:42,409] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:02:42,412] {logging_mixin.py:95} INFO - [2019-03-21 19:02:42,409] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:02:42,412] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:02:42,429] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.054 seconds
[2019-03-21 19:03:48,171] {jobs.py:391} INFO - Started process (PID=38981) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:03:48,176] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:03:48,177] {logging_mixin.py:95} INFO - [2019-03-21 19:03:48,177] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:03:48,194] {logging_mixin.py:95} INFO - [2019-03-21 19:03:48,194] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:05:18,202] {logging_mixin.py:95} INFO - [2019-03-21 19:05:18,202] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:05:18,205] {logging_mixin.py:95} INFO - [2019-03-21 19:05:18,203] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:05:18,205] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:05:18,227] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.056 seconds
[2019-03-21 19:06:23,994] {jobs.py:391} INFO - Started process (PID=40409) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:06:23,999] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:06:24,000] {logging_mixin.py:95} INFO - [2019-03-21 19:06:24,000] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:06:24,017] {logging_mixin.py:95} INFO - [2019-03-21 19:06:24,017] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:07:54,027] {logging_mixin.py:95} INFO - [2019-03-21 19:07:54,027] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:07:54,030] {logging_mixin.py:95} INFO - [2019-03-21 19:07:54,027] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:07:54,030] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:07:54,048] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.054 seconds
[2019-03-21 19:08:59,783] {jobs.py:391} INFO - Started process (PID=41829) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:08:59,789] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:08:59,790] {logging_mixin.py:95} INFO - [2019-03-21 19:08:59,789] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:08:59,809] {logging_mixin.py:95} INFO - [2019-03-21 19:08:59,809] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:10:29,818] {logging_mixin.py:95} INFO - [2019-03-21 19:10:29,818] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:10:29,821] {logging_mixin.py:95} INFO - [2019-03-21 19:10:29,818] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:10:29,821] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:10:29,835] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.052 seconds
[2019-03-21 19:11:35,548] {jobs.py:391} INFO - Started process (PID=43520) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:11:35,554] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:11:35,554] {logging_mixin.py:95} INFO - [2019-03-21 19:11:35,554] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:11:35,572] {logging_mixin.py:95} INFO - [2019-03-21 19:11:35,572] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:13:05,581] {logging_mixin.py:95} INFO - [2019-03-21 19:13:05,581] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:13:05,583] {logging_mixin.py:95} INFO - [2019-03-21 19:13:05,581] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:13:05,584] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:13:05,601] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.052 seconds
[2019-03-21 19:14:11,307] {jobs.py:391} INFO - Started process (PID=45426) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:14:11,313] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:14:11,313] {logging_mixin.py:95} INFO - [2019-03-21 19:14:11,313] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:14:11,331] {logging_mixin.py:95} INFO - [2019-03-21 19:14:11,331] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:15:41,340] {logging_mixin.py:95} INFO - [2019-03-21 19:15:41,340] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:15:41,343] {logging_mixin.py:95} INFO - [2019-03-21 19:15:41,340] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:15:41,343] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:15:41,360] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.053 seconds
[2019-03-21 19:16:47,096] {jobs.py:391} INFO - Started process (PID=47414) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:16:47,101] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:16:47,101] {logging_mixin.py:95} INFO - [2019-03-21 19:16:47,101] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:16:47,122] {logging_mixin.py:95} INFO - [2019-03-21 19:16:47,122] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:18:17,132] {logging_mixin.py:95} INFO - [2019-03-21 19:18:17,132] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:18:17,134] {logging_mixin.py:95} INFO - [2019-03-21 19:18:17,132] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:18:17,135] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:18:17,149] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.053 seconds
[2019-03-21 19:19:22,891] {jobs.py:391} INFO - Started process (PID=49323) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:19:22,897] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:19:22,897] {logging_mixin.py:95} INFO - [2019-03-21 19:19:22,897] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:19:22,918] {logging_mixin.py:95} INFO - [2019-03-21 19:19:22,918] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:20:52,927] {logging_mixin.py:95} INFO - [2019-03-21 19:20:52,927] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:20:52,930] {logging_mixin.py:95} INFO - [2019-03-21 19:20:52,928] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:20:52,930] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:20:52,943] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.052 seconds
[2019-03-21 19:21:58,676] {jobs.py:391} INFO - Started process (PID=51326) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:21:58,682] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:21:58,683] {logging_mixin.py:95} INFO - [2019-03-21 19:21:58,683] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:21:58,700] {logging_mixin.py:95} INFO - [2019-03-21 19:21:58,700] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:23:28,708] {logging_mixin.py:95} INFO - [2019-03-21 19:23:28,708] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:23:28,711] {logging_mixin.py:95} INFO - [2019-03-21 19:23:28,708] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:23:28,711] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:23:28,726] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.050 seconds
[2019-03-21 19:24:34,549] {jobs.py:391} INFO - Started process (PID=53233) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:24:34,554] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:24:34,555] {logging_mixin.py:95} INFO - [2019-03-21 19:24:34,554] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:24:34,572] {logging_mixin.py:95} INFO - [2019-03-21 19:24:34,572] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:26:04,581] {logging_mixin.py:95} INFO - [2019-03-21 19:26:04,581] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:26:04,584] {logging_mixin.py:95} INFO - [2019-03-21 19:26:04,581] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:26:04,584] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:26:04,599] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.050 seconds
[2019-03-21 19:27:10,423] {jobs.py:391} INFO - Started process (PID=55221) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:27:10,428] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:27:10,429] {logging_mixin.py:95} INFO - [2019-03-21 19:27:10,428] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:27:10,446] {logging_mixin.py:95} INFO - [2019-03-21 19:27:10,446] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:28:40,458] {logging_mixin.py:95} INFO - [2019-03-21 19:28:40,458] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:28:40,460] {logging_mixin.py:95} INFO - [2019-03-21 19:28:40,458] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:28:40,461] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:28:40,484] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.061 seconds
[2019-03-21 19:29:46,189] {jobs.py:391} INFO - Started process (PID=56905) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:29:46,195] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:29:46,195] {logging_mixin.py:95} INFO - [2019-03-21 19:29:46,195] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:29:46,215] {logging_mixin.py:95} INFO - [2019-03-21 19:29:46,215] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:31:16,225] {logging_mixin.py:95} INFO - [2019-03-21 19:31:16,225] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:31:16,228] {logging_mixin.py:95} INFO - [2019-03-21 19:31:16,226] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:31:16,228] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:31:16,245] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.056 seconds
[2019-03-21 19:32:22,008] {jobs.py:391} INFO - Started process (PID=58332) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:32:22,014] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:32:22,014] {logging_mixin.py:95} INFO - [2019-03-21 19:32:22,014] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:32:22,034] {logging_mixin.py:95} INFO - [2019-03-21 19:32:22,034] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:33:52,043] {logging_mixin.py:95} INFO - [2019-03-21 19:33:52,043] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:33:52,046] {logging_mixin.py:95} INFO - [2019-03-21 19:33:52,044] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:33:52,046] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:33:52,067] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.059 seconds
[2019-03-21 19:34:57,856] {jobs.py:391} INFO - Started process (PID=59760) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:34:57,862] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:34:57,862] {logging_mixin.py:95} INFO - [2019-03-21 19:34:57,862] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:34:57,882] {logging_mixin.py:95} INFO - [2019-03-21 19:34:57,882] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:36:27,890] {logging_mixin.py:95} INFO - [2019-03-21 19:36:27,890] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:36:27,893] {logging_mixin.py:95} INFO - [2019-03-21 19:36:27,891] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:36:27,893] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:36:27,911] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.055 seconds
[2019-03-21 19:37:33,725] {jobs.py:391} INFO - Started process (PID=61196) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:37:33,732] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:37:33,732] {logging_mixin.py:95} INFO - [2019-03-21 19:37:33,732] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:37:33,752] {logging_mixin.py:95} INFO - [2019-03-21 19:37:33,752] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:39:03,760] {logging_mixin.py:95} INFO - [2019-03-21 19:39:03,760] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:39:03,763] {logging_mixin.py:95} INFO - [2019-03-21 19:39:03,760] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:39:03,763] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:39:03,778] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.053 seconds
[2019-03-21 19:40:09,547] {jobs.py:391} INFO - Started process (PID=62647) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:40:09,552] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:40:09,553] {logging_mixin.py:95} INFO - [2019-03-21 19:40:09,552] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:40:09,570] {logging_mixin.py:95} INFO - [2019-03-21 19:40:09,570] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:41:39,578] {logging_mixin.py:95} INFO - [2019-03-21 19:41:39,578] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:41:39,581] {logging_mixin.py:95} INFO - [2019-03-21 19:41:39,578] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:41:39,581] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:41:39,596] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.049 seconds
[2019-03-21 19:42:45,313] {jobs.py:391} INFO - Started process (PID=64075) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:42:45,319] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:42:45,319] {logging_mixin.py:95} INFO - [2019-03-21 19:42:45,319] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:42:45,336] {logging_mixin.py:95} INFO - [2019-03-21 19:42:45,336] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:44:15,345] {logging_mixin.py:95} INFO - [2019-03-21 19:44:15,345] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:44:15,348] {logging_mixin.py:95} INFO - [2019-03-21 19:44:15,345] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:44:15,348] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:44:15,360] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.047 seconds
[2019-03-21 19:45:21,245] {jobs.py:391} INFO - Started process (PID=65494) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:45:21,252] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:45:21,252] {logging_mixin.py:95} INFO - [2019-03-21 19:45:21,252] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:45:21,271] {logging_mixin.py:95} INFO - [2019-03-21 19:45:21,271] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:46:51,279] {logging_mixin.py:95} INFO - [2019-03-21 19:46:51,279] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:46:51,282] {logging_mixin.py:95} INFO - [2019-03-21 19:46:51,280] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:46:51,282] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:46:51,294] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.048 seconds
[2019-03-21 19:47:57,102] {jobs.py:391} INFO - Started process (PID=66947) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:47:57,107] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:47:57,108] {logging_mixin.py:95} INFO - [2019-03-21 19:47:57,108] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:47:57,128] {logging_mixin.py:95} INFO - [2019-03-21 19:47:57,128] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:49:27,136] {logging_mixin.py:95} INFO - [2019-03-21 19:49:27,136] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:49:27,139] {logging_mixin.py:95} INFO - [2019-03-21 19:49:27,136] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:49:27,139] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:49:27,156] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.054 seconds
[2019-03-21 19:50:32,940] {jobs.py:391} INFO - Started process (PID=68376) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:50:32,946] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:50:32,946] {logging_mixin.py:95} INFO - [2019-03-21 19:50:32,946] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:50:32,967] {logging_mixin.py:95} INFO - [2019-03-21 19:50:32,967] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:52:02,977] {logging_mixin.py:95} INFO - [2019-03-21 19:52:02,977] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:52:02,979] {logging_mixin.py:95} INFO - [2019-03-21 19:52:02,977] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:52:02,980] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:52:02,994] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.054 seconds
[2019-03-21 19:53:08,786] {jobs.py:391} INFO - Started process (PID=69795) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:53:08,792] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:53:08,793] {logging_mixin.py:95} INFO - [2019-03-21 19:53:08,793] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:53:08,813] {logging_mixin.py:95} INFO - [2019-03-21 19:53:08,813] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:54:38,823] {logging_mixin.py:95} INFO - [2019-03-21 19:54:38,822] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:54:38,825] {logging_mixin.py:95} INFO - [2019-03-21 19:54:38,823] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:54:38,825] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:54:38,841] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.056 seconds
[2019-03-21 19:55:44,707] {jobs.py:391} INFO - Started process (PID=71225) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:55:44,713] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:55:44,714] {logging_mixin.py:95} INFO - [2019-03-21 19:55:44,714] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:55:44,734] {logging_mixin.py:95} INFO - [2019-03-21 19:55:44,734] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:57:14,743] {logging_mixin.py:95} INFO - [2019-03-21 19:57:14,742] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:57:14,745] {logging_mixin.py:95} INFO - [2019-03-21 19:57:14,743] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:57:14,745] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:57:14,759] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.052 seconds
[2019-03-21 19:58:20,536] {jobs.py:391} INFO - Started process (PID=72676) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:58:20,541] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 19:58:20,541] {logging_mixin.py:95} INFO - [2019-03-21 19:58:20,541] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:58:20,559] {logging_mixin.py:95} INFO - [2019-03-21 19:58:20,559] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 19:59:50,568] {logging_mixin.py:95} INFO - [2019-03-21 19:59:50,568] {timeout.py:41} ERROR - Process timed out
[2019-03-21 19:59:50,570] {logging_mixin.py:95} INFO - [2019-03-21 19:59:50,568] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 19:59:50,571] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 19:59:50,588] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.052 seconds
[2019-03-21 20:00:56,391] {jobs.py:391} INFO - Started process (PID=74103) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:00:56,396] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:00:56,396] {logging_mixin.py:95} INFO - [2019-03-21 20:00:56,396] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:00:56,414] {logging_mixin.py:95} INFO - [2019-03-21 20:00:56,414] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:02:26,422] {logging_mixin.py:95} INFO - [2019-03-21 20:02:26,421] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:02:26,425] {logging_mixin.py:95} INFO - [2019-03-21 20:02:26,422] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:02:26,425] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:02:26,442] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.052 seconds
[2019-03-21 20:03:34,385] {jobs.py:391} INFO - Started process (PID=76013) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:03:34,389] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:03:34,390] {logging_mixin.py:95} INFO - [2019-03-21 20:03:34,390] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:03:34,408] {logging_mixin.py:95} INFO - [2019-03-21 20:03:34,408] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:05:04,416] {logging_mixin.py:95} INFO - [2019-03-21 20:05:04,416] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:05:04,419] {logging_mixin.py:95} INFO - [2019-03-21 20:05:04,416] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:05:04,419] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:05:04,433] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.048 seconds
[2019-03-21 20:06:11,761] {jobs.py:391} INFO - Started process (PID=78249) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:06:11,766] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:06:11,766] {logging_mixin.py:95} INFO - [2019-03-21 20:06:11,766] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:06:11,783] {logging_mixin.py:95} INFO - [2019-03-21 20:06:11,783] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:07:41,794] {logging_mixin.py:95} INFO - [2019-03-21 20:07:41,794] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:07:41,797] {logging_mixin.py:95} INFO - [2019-03-21 20:07:41,794] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:07:41,797] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:07:41,809] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.048 seconds
[2019-03-21 20:08:48,110] {jobs.py:391} INFO - Started process (PID=80533) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:08:48,116] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:08:48,116] {logging_mixin.py:95} INFO - [2019-03-21 20:08:48,116] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:08:48,136] {logging_mixin.py:95} INFO - [2019-03-21 20:08:48,136] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:10:18,146] {logging_mixin.py:95} INFO - [2019-03-21 20:10:18,145] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:10:18,148] {logging_mixin.py:95} INFO - [2019-03-21 20:10:18,146] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:10:18,148] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:10:18,163] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.053 seconds
[2019-03-21 20:11:25,372] {jobs.py:391} INFO - Started process (PID=82770) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:11:25,377] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:11:25,377] {logging_mixin.py:95} INFO - [2019-03-21 20:11:25,377] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:11:25,394] {logging_mixin.py:95} INFO - [2019-03-21 20:11:25,394] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:12:55,402] {logging_mixin.py:95} INFO - [2019-03-21 20:12:55,402] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:12:55,405] {logging_mixin.py:95} INFO - [2019-03-21 20:12:55,402] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:12:55,405] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:12:55,419] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.047 seconds
[2019-03-21 20:14:01,459] {jobs.py:391} INFO - Started process (PID=85206) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:14:01,465] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:14:01,465] {logging_mixin.py:95} INFO - [2019-03-21 20:14:01,465] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:14:01,482] {logging_mixin.py:95} INFO - [2019-03-21 20:14:01,482] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:15:31,490] {logging_mixin.py:95} INFO - [2019-03-21 20:15:31,490] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:15:31,493] {logging_mixin.py:95} INFO - [2019-03-21 20:15:31,490] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:15:31,493] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:15:31,509] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.050 seconds
[2019-03-21 20:16:38,010] {jobs.py:391} INFO - Started process (PID=88106) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:16:38,017] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:16:38,018] {logging_mixin.py:95} INFO - [2019-03-21 20:16:38,018] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:16:38,034] {logging_mixin.py:95} INFO - [2019-03-21 20:16:38,034] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:18:08,061] {logging_mixin.py:95} INFO - [2019-03-21 20:18:08,061] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:18:08,063] {logging_mixin.py:95} INFO - [2019-03-21 20:18:08,061] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:18:08,064] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:18:08,155] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.145 seconds
[2019-03-21 20:19:16,962] {jobs.py:391} INFO - Started process (PID=92905) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:19:17,000] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:19:17,000] {logging_mixin.py:95} INFO - [2019-03-21 20:19:17,000] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:19:17,019] {logging_mixin.py:95} INFO - [2019-03-21 20:19:17,019] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:20:47,039] {logging_mixin.py:95} INFO - [2019-03-21 20:20:47,039] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:20:47,041] {logging_mixin.py:95} INFO - [2019-03-21 20:20:47,039] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:20:47,042] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:20:47,057] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.095 seconds
[2019-03-21 20:21:55,233] {jobs.py:391} INFO - Started process (PID=97694) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:21:55,255] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:21:55,255] {logging_mixin.py:95} INFO - [2019-03-21 20:21:55,255] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:21:55,335] {logging_mixin.py:95} INFO - [2019-03-21 20:21:55,335] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:23:25,344] {logging_mixin.py:95} INFO - [2019-03-21 20:23:25,344] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:23:25,347] {logging_mixin.py:95} INFO - [2019-03-21 20:23:25,345] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:23:25,347] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:23:25,361] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.129 seconds
[2019-03-21 20:24:33,335] {jobs.py:391} INFO - Started process (PID=102243) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:24:33,341] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:24:33,341] {logging_mixin.py:95} INFO - [2019-03-21 20:24:33,341] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:24:33,359] {logging_mixin.py:95} INFO - [2019-03-21 20:24:33,359] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:26:03,379] {logging_mixin.py:95} INFO - [2019-03-21 20:26:03,379] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:26:03,382] {logging_mixin.py:95} INFO - [2019-03-21 20:26:03,379] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:26:03,382] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:26:03,451] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.116 seconds
[2019-03-21 20:27:09,886] {jobs.py:391} INFO - Started process (PID=106773) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:27:09,890] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:27:09,891] {logging_mixin.py:95} INFO - [2019-03-21 20:27:09,891] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:27:09,909] {logging_mixin.py:95} INFO - [2019-03-21 20:27:09,909] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:28:39,935] {logging_mixin.py:95} INFO - [2019-03-21 20:28:39,935] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:28:39,939] {logging_mixin.py:95} INFO - [2019-03-21 20:28:39,936] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:28:39,939] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:28:40,025] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.139 seconds
[2019-03-21 20:29:47,191] {jobs.py:391} INFO - Started process (PID=111189) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:29:47,239] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:29:47,240] {logging_mixin.py:95} INFO - [2019-03-21 20:29:47,239] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:29:47,278] {logging_mixin.py:95} INFO - [2019-03-21 20:29:47,278] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:31:17,287] {logging_mixin.py:95} INFO - [2019-03-21 20:31:17,287] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:31:17,290] {logging_mixin.py:95} INFO - [2019-03-21 20:31:17,287] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:31:17,290] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:31:17,303] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.112 seconds
[2019-03-21 20:32:25,024] {jobs.py:391} INFO - Started process (PID=115395) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:32:25,033] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:32:25,034] {logging_mixin.py:95} INFO - [2019-03-21 20:32:25,033] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:32:25,060] {logging_mixin.py:95} INFO - [2019-03-21 20:32:25,060] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:33:55,082] {logging_mixin.py:95} INFO - [2019-03-21 20:33:55,081] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:33:55,084] {logging_mixin.py:95} INFO - [2019-03-21 20:33:55,082] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:33:55,084] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:33:55,127] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.103 seconds
[2019-03-21 20:35:01,313] {jobs.py:391} INFO - Started process (PID=120229) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:35:01,319] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:35:01,320] {logging_mixin.py:95} INFO - [2019-03-21 20:35:01,319] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:35:01,344] {logging_mixin.py:95} INFO - [2019-03-21 20:35:01,344] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:36:31,365] {logging_mixin.py:95} INFO - [2019-03-21 20:36:31,365] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:36:31,367] {logging_mixin.py:95} INFO - [2019-03-21 20:36:31,365] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:36:31,367] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:36:31,385] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.071 seconds
[2019-03-21 20:37:42,169] {jobs.py:391} INFO - Started process (PID=125118) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:37:42,212] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:37:42,213] {logging_mixin.py:95} INFO - [2019-03-21 20:37:42,213] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:37:42,237] {logging_mixin.py:95} INFO - [2019-03-21 20:37:42,236] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:39:12,251] {logging_mixin.py:95} INFO - [2019-03-21 20:39:12,251] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:39:12,254] {logging_mixin.py:95} INFO - [2019-03-21 20:39:12,252] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:39:12,254] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:39:12,272] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.104 seconds
[2019-03-21 20:40:20,911] {jobs.py:391} INFO - Started process (PID=129944) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:40:20,949] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:40:20,949] {logging_mixin.py:95} INFO - [2019-03-21 20:40:20,949] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:40:20,968] {logging_mixin.py:95} INFO - [2019-03-21 20:40:20,968] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:41:50,977] {logging_mixin.py:95} INFO - [2019-03-21 20:41:50,977] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:41:50,980] {logging_mixin.py:95} INFO - [2019-03-21 20:41:50,977] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:41:50,980] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:41:51,023] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.112 seconds
[2019-03-21 20:42:57,145] {jobs.py:391} INFO - Started process (PID=134991) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:42:57,151] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:42:57,151] {logging_mixin.py:95} INFO - [2019-03-21 20:42:57,151] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:42:57,168] {logging_mixin.py:95} INFO - [2019-03-21 20:42:57,168] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:44:27,178] {logging_mixin.py:95} INFO - [2019-03-21 20:44:27,178] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:44:27,180] {logging_mixin.py:95} INFO - [2019-03-21 20:44:27,178] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:44:27,180] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:44:27,195] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.050 seconds
[2019-03-21 20:45:35,299] {jobs.py:391} INFO - Started process (PID=139954) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:45:35,307] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:45:35,308] {logging_mixin.py:95} INFO - [2019-03-21 20:45:35,308] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:45:35,329] {logging_mixin.py:95} INFO - [2019-03-21 20:45:35,329] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:47:05,340] {logging_mixin.py:95} INFO - [2019-03-21 20:47:05,340] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:47:05,342] {logging_mixin.py:95} INFO - [2019-03-21 20:47:05,340] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:47:05,343] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:47:05,362] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.062 seconds
[2019-03-21 20:48:15,032] {jobs.py:391} INFO - Started process (PID=145021) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:48:15,037] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:48:15,037] {logging_mixin.py:95} INFO - [2019-03-21 20:48:15,037] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:48:15,054] {logging_mixin.py:95} INFO - [2019-03-21 20:48:15,054] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:49:45,070] {logging_mixin.py:95} INFO - [2019-03-21 20:49:45,070] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:49:45,074] {logging_mixin.py:95} INFO - [2019-03-21 20:49:45,070] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:49:45,074] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:49:45,114] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.083 seconds
[2019-03-21 20:50:51,683] {jobs.py:391} INFO - Started process (PID=150392) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:50:51,689] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:50:51,689] {logging_mixin.py:95} INFO - [2019-03-21 20:50:51,689] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:50:51,706] {logging_mixin.py:95} INFO - [2019-03-21 20:50:51,706] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:52:21,715] {logging_mixin.py:95} INFO - [2019-03-21 20:52:21,714] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:52:21,717] {logging_mixin.py:95} INFO - [2019-03-21 20:52:21,715] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:52:21,717] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:52:21,729] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.046 seconds
[2019-03-21 20:53:27,931] {jobs.py:391} INFO - Started process (PID=155550) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:53:27,940] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:53:27,940] {logging_mixin.py:95} INFO - [2019-03-21 20:53:27,940] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:53:27,964] {logging_mixin.py:95} INFO - [2019-03-21 20:53:27,964] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:54:57,976] {logging_mixin.py:95} INFO - [2019-03-21 20:54:57,976] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:54:57,979] {logging_mixin.py:95} INFO - [2019-03-21 20:54:57,976] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:54:57,979] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:54:58,052] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.121 seconds
[2019-03-21 20:56:07,933] {jobs.py:391} INFO - Started process (PID=162113) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:56:07,981] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:56:07,981] {logging_mixin.py:95} INFO - [2019-03-21 20:56:07,981] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:56:08,000] {logging_mixin.py:95} INFO - [2019-03-21 20:56:08,000] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 20:57:38,022] {logging_mixin.py:95} INFO - [2019-03-21 20:57:38,022] {timeout.py:41} ERROR - Process timed out
[2019-03-21 20:57:38,025] {logging_mixin.py:95} INFO - [2019-03-21 20:57:38,023] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 20:57:38,025] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:57:38,123] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.190 seconds
[2019-03-21 20:58:49,313] {jobs.py:391} INFO - Started process (PID=168767) to work on /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:58:49,360] {jobs.py:1675} INFO - Processing file /home/rsandroni/airflow/dags/sql_test.py for tasks to queue
[2019-03-21 20:58:49,361] {logging_mixin.py:95} INFO - [2019-03-21 20:58:49,361] {models.py:273} INFO - Filling up the DagBag from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 20:58:49,403] {logging_mixin.py:95} INFO - [2019-03-21 20:58:49,403] {base_hook.py:83} INFO - Using connection to: id: mssql_default. Host: 172.27.16.212, Port: 5555, Schema: DataEngineering, Login: rafael.sandroni, Password: XXXXXXXX, extra: {}
[2019-03-21 21:00:19,443] {logging_mixin.py:95} INFO - [2019-03-21 21:00:19,443] {timeout.py:41} ERROR - Process timed out
[2019-03-21 21:00:19,446] {logging_mixin.py:95} INFO - [2019-03-21 21:00:19,443] {models.py:377} ERROR - Failed to import: /home/rsandroni/airflow/dags/sql_test.py
Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib64/python3.6/encodings/__init__.py", line 71, in search_function
    def search_function(encoding):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/utils/timeout.py", line 42, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/rsandroni/airflow/env/lib/python3.6/site-packages/airflow/models.py", line 374, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/rsandroni/airflow/env/lib64/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/rsandroni/airflow/dags/sql_test.py", line 67, in <module>
    Op = CustomOperator()
  File "/home/rsandroni/airflow/dags/sql_test.py", line 39, in __init__
    self.conn = mssql.get_conn()
  File "/home/rsandroni/airflow/dags/MssqlPyodbc.py", line 117, in get_conn
    conn = pyodbc.connect(connection_string,timeout=45)
SystemError: <class 'pyodbc.Error'> returned a result with an error set
[2019-03-21 21:00:19,447] {jobs.py:1689} WARNING - No viable dags retrieved from /home/rsandroni/airflow/dags/sql_test.py
[2019-03-21 21:00:19,552] {jobs.py:399} INFO - Processing /home/rsandroni/airflow/dags/sql_test.py took 90.239 seconds
